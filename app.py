# -----------------------------------------------------------------------------
# 1. BULUT VERÄ°TABANI YAMASI (Mecburi - Dokunma)
# -----------------------------------------------------------------------------
import sys
try:
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

# -----------------------------------------------------------------------------
# KÃœTÃœPHANELER
# -----------------------------------------------------------------------------
import streamlit as st
import os
import shutil
import time
import json
from dotenv import load_dotenv

# Eski ve Sorunsuz Importlar
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain

# Kendi fonksiyonun
from data_ingestion import load_and_process_pdfs

# -----------------------------------------------------------------------------
# AYARLAR VE TASARIM
# -----------------------------------------------------------------------------
load_dotenv()
st.set_page_config(page_title="KampÃ¼s AsistanÄ±", page_icon="ğŸ“", layout="wide")

PERSIST_DIRECTORY = "./chroma_db_store"
USERS_FILE = "users.json"

# --- YARDIMCI FONKSÄ°YONLAR ---

def load_users():
    if not os.path.exists(USERS_FILE):
        return {}
    with open(USERS_FILE, "r") as f:
        return json.load(f)

def save_users(users):
    with open(USERS_FILE, "w") as f:
        json.dump(users, f)

@st.cache_resource
def get_vector_db():
    embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    if os.path.exists(PERSIST_DIRECTORY):
        vectordb = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embedding)
        if vectordb._collection.count() > 0:
            return vectordb
    return None

def get_llm_chain(vectordb):
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3)
    
    template = """
    Sen Ã¼niversite mevzuatlarÄ± konusunda uzman, arkadaÅŸ canlÄ±sÄ± bir asistansÄ±n.
    
    Kurallar:
    1. SADECE aÅŸaÄŸÄ±daki baÄŸlamÄ± kullan.
    2. CevabÄ± maddeler halinde ve anlaÅŸÄ±lÄ±r ver.
    3. Bilgi yoksa "YÃ¶netmeliklerde bu bilgiye rastlayamadÄ±m." de.
    
    BaÄŸlam: {context}
    Soru: {question}
    GeÃ§miÅŸ: {chat_history}
    
    Cevap:
    """
    PROMPT = PromptTemplate(template=template, input_variables=["chat_history", "context", "question"])
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 5}),
        return_source_documents=True,
        combine_docs_chain_kwargs={"prompt": PROMPT}
    )

# -----------------------------------------------------------------------------
# ARAYÃœZ (SIDEBAR)
# -----------------------------------------------------------------------------

if "logged_in" not in st.session_state: st.session_state.logged_in = False
if "messages" not in st.session_state: st.session_state.messages = []
if "chat_history" not in st.session_state: st.session_state.chat_history = []

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3406/3406987.png", width=80)
    st.title("ğŸ“ Mevzuat Paneli")
    
    users_db = load_users()

    if not st.session_state.logged_in:
        # --- SEKME YAPISI (SENÄ°N Ä°STEDÄ°ÄÄ°N GÄ°BÄ°) ---
        tab1, tab2 = st.tabs(["ğŸ”‘ GiriÅŸ Yap", "ğŸ“ KayÄ±t Ol"])
        
        with tab1:
            st.subheader("HoÅŸ Geldiniz")
            u_login = st.text_input("KullanÄ±cÄ± AdÄ±", key="login_user")
            p_login = st.text_input("Åifre", type="password", key="login_pass")
            
            if st.button("GiriÅŸ Yap", type="primary", use_container_width=True):
                if u_login in users_db and users_db[u_login]["password"] == p_login:
                    st.session_state.logged_in = True
                    st.session_state.username = u_login
                    st.session_state.role = users_db[u_login]["role"]
                    st.success("GiriÅŸ baÅŸarÄ±lÄ±!")
                    time.sleep(0.5)
                    st.rerun()
                else:
                    st.error("HatalÄ± kullanÄ±cÄ± adÄ± veya ÅŸifre!")

        with tab2:
            st.subheader("Yeni Hesap")
            new_user = st.text_input("KullanÄ±cÄ± AdÄ± Belirle", key="reg_user")
            new_pass = st.text_input("Åifre Belirle", type="password", key="reg_pass")
            
            if st.button("KayÄ±t Ol", type="secondary", use_container_width=True):
                if new_user and new_pass:
                    if new_user in users_db:
                        st.warning("Bu kullanÄ±cÄ± adÄ± zaten alÄ±nmÄ±ÅŸ.")
                    else:
                        users_db[new_user] = {"password": new_pass, "role": "student"}
                        save_users(users_db)
                        st.success("KayÄ±t baÅŸarÄ±lÄ±! Åimdi 'GiriÅŸ Yap' sekmesinden girebilirsin.")
                else:
                    st.warning("LÃ¼tfen tÃ¼m alanlarÄ± doldur.")

    else:
        # --- GÄ°RÄ°Å YAPILINCA GÃ–RÃœNEN KISIM ---
        st.success(f"ğŸ‘¤ Aktif KullanÄ±cÄ±: **{st.session_state.username}**")
        
        if st.session_state.get("role") == "admin":
            st.divider()
            st.markdown("### ğŸ› ï¸ YÃ¶netici Paneli")
            files = st.file_uploader("PDF YÃ¼kle", type=["pdf"], accept_multiple_files=True)
            
            if st.button("Sistemi GÃ¼ncelle", type="primary"):
                if files:
                    if not os.path.exists("./veriler"): os.makedirs("./veriler")
                    for f in files:
                        with open(os.path.join("./veriler", f.name), "wb") as w: w.write(f.getbuffer())
                    
                    if os.path.exists(PERSIST_DIRECTORY): shutil.rmtree(PERSIST_DIRECTORY)
                    
                    with st.status("VeritabanÄ± gÃ¼ncelleniyor...", expanded=True) as status:
                        st.write("ğŸ“„ Dosyalar okunuyor...")
                        chunks = load_and_process_pdfs()
                        st.write("ğŸ§  VektÃ¶r veritabanÄ± kuruluyor...")
                        if chunks:
                            Chroma.from_documents(chunks, HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"), persist_directory=PERSIST_DIRECTORY)
                            status.update(label="âœ… Ä°ÅŸlem BaÅŸarÄ±lÄ±!", state="complete")
                            time.sleep(1)
                            st.rerun()
        
        st.divider()
        if st.button("Ã‡Ä±kÄ±ÅŸ Yap", use_container_width=True):
            st.session_state.logged_in = False
            st.rerun()

# -----------------------------------------------------------------------------
# ANA SOHBET EKRANI
# -----------------------------------------------------------------------------

st.title("ğŸ›ï¸ KampÃ¼s Mevzuat AsistanÄ±")
st.markdown("Merhaba! YÃ¶netmelikler hakkÄ±nda aklÄ±na takÄ±lan her ÅŸeyi sorabilirsin.")

if st.session_state.logged_in:
    vectordb = get_vector_db()
    
    if vectordb:
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

        if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.chat_message("assistant"):
                placeholder = st.empty()
                placeholder.markdown("âš¡ *DÃ¼ÅŸÃ¼nÃ¼yor...*")
                
                try:
                    chain = get_llm_chain(vectordb)
                    res = chain({"question": prompt, "chat_history": st.session_state.chat_history})
                    answer = res['answer']
                    
                    # KaynaklarÄ± GÃ¼zelleÅŸtirme
                    sources = []
                    seen = set()
                    for doc in res['source_documents']:
                        name = os.path.basename(doc.metadata.get('source', 'Belge'))
                        page = doc.metadata.get('page', 0) + 1
                        key = f"{name} (Sayfa {page})"
                        if key not in seen:
                            sources.append(key)
                            seen.add(key)
                    
                    final_text = f"{answer}\n\nğŸ“š **Kaynaklar:**\n" + "\n".join([f"- {s}" for s in sources])
                    
                    # Daktilo Efekti
                    def stream():
                        for word in final_text.split(" "):
                            yield word + " "
                            time.sleep(0.02)
                    placeholder.write_stream(stream)
                    
                    st.session_state.messages.append({"role": "assistant", "content": final_text})
                    st.session_state.chat_history.append((prompt, answer))
                
                except Exception as e:
                    placeholder.error(f"Hata oluÅŸtu: {e}")
    else:
        st.info("ğŸ‘‹ HoÅŸ geldin! Sistem ÅŸu an boÅŸ gÃ¶rÃ¼nÃ¼yor. LÃ¼tfen yÃ¶netici hesabÄ±yla giriÅŸ yapÄ±p PDF yÃ¼kleyin.")

else:
    st.warning("ğŸ‘ˆ LÃ¼tfen sol taraftaki panelden **GiriÅŸ YapÄ±n** veya **KayÄ±t Olun**.")