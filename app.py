# -----------------------------------------------------------------------------
# 1. BULUT VERÄ°TABANI YAMASI (EN ÃœSTTE OLMALI)
# -----------------------------------------------------------------------------
import sys
import os

try:
    # Bu kÄ±sÄ±m sadece Streamlit Cloud'da (Linux) Ã§alÄ±ÅŸÄ±r
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    # Local bilgisayarda (Windows) bu kÃ¼tÃ¼phane yoktur,
    # standart sqlite3 ile devam et.
    pass

# -----------------------------------------------------------------------------
# KÃœTÃœPHANELER
# -----------------------------------------------------------------------------
import streamlit as st
import shutil
import time
import json
import datetime
from dotenv import load_dotenv

# RAG ve LangChain BileÅŸenleri
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain

# Kendi fonksiyonlarÄ±mÄ±z (data_ingestion.py dosyanÄ±n olduÄŸundan emin ol)
from data_ingestion import load_and_process_pdfs

# -----------------------------------------------------------------------------
# AYARLAR VE SABÄ°TLER
# -----------------------------------------------------------------------------
load_dotenv()

st.set_page_config(
    page_title="KampÃ¼s AsistanÄ±",
    page_icon="ğŸ“",
    layout="wide"
)

PERSIST_DIRECTORY = "./chroma_db_store"
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# -----------------------------------------------------------------------------
# FONKSÄ°YONLAR
# -----------------------------------------------------------------------------

@st.cache_resource
def get_vector_db():
    """
    VeritabanÄ±nÄ± yÃ¼kler. EÄŸer 'Doku UyuÅŸmazlÄ±ÄŸÄ±' (Windows->Linux) yÃ¼zÃ¼nden
    okuyamazsa, './veriler' klasÃ¶rÃ¼ndeki PDF'lerden anÄ±nda sÄ±fÄ±rdan kurar.
    """
    embedding = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
    
    # 1. YÃ–NTEM: Mevcut veritabanÄ±nÄ± okumayÄ± dene
    if os.path.exists(PERSIST_DIRECTORY):
        try:
            print("ğŸ’¾ Mevcut veritabanÄ± kontrol ediliyor...")
            vectordb = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embedding)
            
            # Basit bir okuma testi yapalÄ±m
            if vectordb._collection.count() > 0:
                print("âœ… VeritabanÄ± saÄŸlam, yÃ¼klendi.")
                return vectordb
        except Exception as e:
            print(f"âš ï¸ VeritabanÄ± okunamadÄ± (OS UyuÅŸmazlÄ±ÄŸÄ±): {e}")

    # 2. YÃ–NTEM: OkuyamadÄ±ysa veya yoksa SIFIRDAN KUR (Auto-Healing)
    print("ğŸ”„ Otomatik OnarÄ±m Modu: VeritabanÄ± sÄ±fÄ±rdan kuruluyor...")
    
    if os.path.exists("./veriler") and os.listdir("./veriler"):
        try:
            with st.spinner("Sistem ilk kez hazÄ±rlanÄ±yor, lÃ¼tfen bekleyiniz..."):
                # PDF'leri iÅŸle
                chunks = load_and_process_pdfs()
                if chunks:
                    # SÄ±fÄ±rdan veritabanÄ± oluÅŸtur
                    vectordb = Chroma.from_documents(chunks, embedding, persist_directory=PERSIST_DIRECTORY)
                    print("âœ… Otomatik kurulum tamamlandÄ±!")
                    return vectordb
        except Exception as e:
            st.error(f"âŒ Kritik Hata: Otomatik kurulum yapÄ±lamadÄ±. {e}")
            return None
    else:
        # Veriler klasÃ¶rÃ¼ de boÅŸsa yapacak bir ÅŸey yok
        return None

def get_llm_chain(vectordb):
    """
    Yapay Zeka ayarlarÄ± ve Prompt ÅŸablonu.
    """
    # Gemini 1.5 Flash (HÄ±zlÄ± ve Ucuz)
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.3)
    
    # --- AKILLI PROMPT (Tarih ve GÃ¼n HesabÄ± Yapabilen) ---
    custom_template = """
    Sen Ã¼niversite mevzuatlarÄ± konusunda uzman, yardÄ±msever bir asistansÄ±n.
    AÅŸaÄŸÄ±daki sohbet geÃ§miÅŸini ve baÄŸlamÄ± (context) kullanarak soruyu cevapla.
    
    Kurallar:
    1. Mevzuat maddeleri (sÃ¼reler, cezalar, notlar) iÃ§in SADECE verilen baÄŸlamÄ± kullan. Asla uydurma.
    2. Tarih hesaplamalarÄ±, "Hafta sonu iÅŸ gÃ¼nÃ¼ mÃ¼dÃ¼r?", "BugÃ¼n pazartesi ise 5 gÃ¼n sonra ne olur?" gibi mantÄ±k sorularÄ± iÃ§in KENDÄ° GENEL BÄ°LGÄ°NÄ° kullan.
    3. BaÄŸlamda bilgi yoksa "YÃ¶netmeliklerde bu bilgiye rastlayamadÄ±m." de.
    4. CevabÄ± maddeleri referans gÃ¶stererek ver.
    
    Sohbet GeÃ§miÅŸi:
    {chat_history}
    
    BaÄŸlam:
    {context}
    
    Soru: {question}
    Cevap:
    """
    
    PROMPT = PromptTemplate(template=custom_template, input_variables=["chat_history", "context", "question"])
    
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 5}),
        return_source_documents=True,
        combine_docs_chain_kwargs={"prompt": PROMPT},
        verbose=False
    )
    return qa_chain

# -----------------------------------------------------------------------------
# ARAYÃœZ (SIDEBAR - GÄ°RÄ°Å VE PANEL)
# -----------------------------------------------------------------------------

# Oturum Durumu BaÅŸlatma
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "username" not in st.session_state:
    st.session_state.username = ""
if "messages" not in st.session_state:
    st.session_state.messages = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

with st.sidebar:
    st.header("âš™ï¸ Panel")
    
    # KullanÄ±cÄ± Verilerini YÃ¼kle
    users = {}
    try:
        with open("users.json", "r") as f:
            users = json.load(f)
    except FileNotFoundError:
        st.error("KullanÄ±cÄ± veritabanÄ± (users.json) bulunamadÄ±.")

    # GiriÅŸ EkranÄ±
    if not st.session_state.logged_in:
        username_input = st.text_input("KullanÄ±cÄ± AdÄ±")
        password_input = st.text_input("Åifre", type="password")
        
        if st.button("GiriÅŸ Yap"):
            if username_input in users and users[username_input]["password"] == password_input:
                st.session_state.logged_in = True
                st.session_state.username = username_input
                st.session_state.role = users[username_input]["role"]
                st.success(f"HoÅŸ geldin {username_input}!")
                st.rerun()
            else:
                st.error("HatalÄ± kullanÄ±cÄ± adÄ± veya ÅŸifre!")
    
    else:
        # GiriÅŸ YapÄ±lmÄ±ÅŸ Durum
        st.info(f"Ã–ÄŸrenci: {st.session_state.username}")
        st.caption("Soru sorarak yÃ¶netmelikleri Ã¶ÄŸrenebilirsin.")

        # --- YÃ–NETÄ°CÄ° Ã–ZEL ALANI ---
        if st.session_state.role == "admin":
            st.divider()
            st.subheader("ğŸ”§ YÃ¶netici AraÃ§larÄ±")
            
            uploaded_files = st.file_uploader("PDF YÃ¼kle (YÃ¶netmelik)", type=["pdf"], accept_multiple_files=True)
            
            if st.button("VeritabanÄ±nÄ± GÃ¼ncelle"):
                if uploaded_files:
                    if not os.path.exists("./veriler"):
                        os.makedirs("./veriler")
                    
                    # DosyalarÄ± kaydet
                    for file in uploaded_files:
                        with open(os.path.join("./veriler", file.name), "wb") as f:
                            f.write(file.getbuffer())
                    
                    st.toast("PDF'ler iÅŸleniyor, lÃ¼tfen bekleyin...", icon="â³")
                    
                    # VeritabanÄ±nÄ± sÄ±fÄ±rla ve yeniden kur
                    if os.path.exists(PERSIST_DIRECTORY):
                        shutil.rmtree(PERSIST_DIRECTORY)
                    
                    chunks = load_and_process_pdfs()
                    if chunks:
                        embedding = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
                        Chroma.from_documents(chunks, embedding, persist_directory=PERSIST_DIRECTORY)
                        st.success("âœ… GÃœNCELLEME TAMAMLANDI!")
                        time.sleep(1)
                        st.rerun()
                else:
                    st.warning("LÃ¼tfen Ã¶nce dosya seÃ§in.")

        if st.button("Ã‡Ä±kÄ±ÅŸ Yap"):
            st.session_state.logged_in = False
            st.session_state.username = ""
            st.session_state.messages = []
            st.rerun()

# -----------------------------------------------------------------------------
# ANA SOHBET EKRANI
# -----------------------------------------------------------------------------

st.title("ğŸ“ Mevzuat AsistanÄ±")

if st.session_state.logged_in:
    # 1. VeritabanÄ±nÄ± Getir (Auto-Healing ile)
    vectordb = get_vector_db()

    if vectordb is None:
        st.error("ğŸš¨ VeritabanÄ± ÅŸu an boÅŸ ve oluÅŸturulamadÄ±. LÃ¼tfen yÃ¶neticinin PDF yÃ¼klemesini bekleyin.")
    else:
        # 2. Sohbet GeÃ§miÅŸini GÃ¶ster
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # 3. Yeni Soru GiriÅŸi
        if prompt := st.chat_input("Sorunuzu yazÄ±n..."):
            # KullanÄ±cÄ± mesajÄ±nÄ± ekle
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # Cevap Ãœretimi
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                message_placeholder.markdown("âš¡ *DÃ¼ÅŸÃ¼nÃ¼yor...*")
                
                try:
                    qa_chain = get_llm_chain(vectordb)
                    res = qa_chain({"question": prompt, "chat_history": st.session_state.chat_history})
                    
                    answer_text = res['answer']
                    source_docs = res['source_documents']
                    
                    # KaynaklarÄ± dÃ¼zenle
                    source_map = {}
                    for doc in source_docs:
                        source_name = os.path.basename(doc.metadata.get('source', 'Bilinmiyor'))
                        page_num = doc.metadata.get('page', 0) + 1
                        if source_name not in source_map: source_map[source_name] = set()
                        source_map[source_name].add(page_num)
                    
                    formatted_sources = []
                    for name, pages in source_map.items():
                        sorted_pages = sorted(list(pages))
                        page_str = ", ".join(map(str, sorted_pages))
                        formatted_sources.append(f"**{name}** (Sayfalar: {page_str})")
                    
                    final_answer = f"{answer_text}\n\nğŸ“š **Kaynaklar:**\n" + "\n".join([f"- {s}" for s in formatted_sources])
                    
                    # --- DAKTÄ°LO EFEKTÄ° (STREAMING) ---
                    def stream_data():
                        for word in final_answer.split(" "):
                            yield word + " "
                            time.sleep(0.02)
                            
                    message_placeholder.write_stream(stream_data)
                    # ----------------------------------

                    # GeÃ§miÅŸe kaydet
                    st.session_state.messages.append({"role": "assistant", "content": final_answer})
                    st.session_state.chat_history.append((prompt, answer_text))
                
                except Exception as e:
                    message_placeholder.error(f"Bir hata oluÅŸtu: {str(e)}")

else:
    st.info("LÃ¼tfen sol taraftaki panelden giriÅŸ yapÄ±nÄ±z.")

# -----------------------------------------------------------------------------
# SOHBETÄ° Ä°NDÄ°R (SAYFANIN EN ALTI)
# -----------------------------------------------------------------------------
if st.session_state.messages:
    st.markdown("---")
    chat_text = "ğŸ“ MEVZUAT ASÄ°STANI - SOHBET KAYDI\n"
    chat_text += f"Tarih: {datetime.datetime.now().strftime('%d.%m.%Y %H:%M')}\n"
    chat_text += "-"*50 + "\n\n"
    
    for msg in st.session_state.messages:
        role = "ASÄ°STAN" if msg["role"] == "assistant" else "Ã–ÄRENCÄ°"
        content = msg["content"]
        chat_text += f"[{role}]: {content}\n\n"
        chat_text += "-"*30 + "\n\n"

    st.download_button(
        label="ğŸ“¥ Sohbeti Ä°ndir (.txt)",
        data=chat_text,
        file_name="mevzuat_sohbeti.txt",
        mime="text/plain",
        use_container_width=True
    )