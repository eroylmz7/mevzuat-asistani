# -----------------------------------------------------------------------------
# 1. BULUT VERÄ°TABANI YAMASI (Mecburi - Dokunma)
# -----------------------------------------------------------------------------
import sys
try:
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

# -----------------------------------------------------------------------------
# KÃœTÃœPHANELER
# -----------------------------------------------------------------------------
import streamlit as st
import os
import shutil
import time
import json
from dotenv import load_dotenv

# Eski ve Sorunsuz Importlar (GÃ¶rsel Ã¶ÄŸeler iÃ§in gerekli)
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain

# Kendi fonksiyonun
from data_ingestion import load_and_process_pdfs

# -----------------------------------------------------------------------------
# AYARLAR VE TASARIM
# -----------------------------------------------------------------------------
load_dotenv()
st.set_page_config(page_title="KampÃ¼s AsistanÄ±", page_icon="ğŸ“", layout="wide")

PERSIST_DIRECTORY = "./chroma_db_store"

# --- FONKSÄ°YONLAR ---

@st.cache_resource
def get_vector_db():
    # VeritabanÄ± var mÄ± kontrol et
    embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    
    if os.path.exists(PERSIST_DIRECTORY):
        vectordb = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embedding)
        if vectordb._collection.count() > 0:
            return vectordb
    return None

def get_llm_chain(vectordb):
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3)
    
    # O eski gÃ¼zel cevap formatÄ±
    template = """
    Sen Ã¼niversite mevzuatlarÄ± konusunda uzman, yardÄ±msever bir asistansÄ±n.
    
    Kurallar:
    1. SADECE aÅŸaÄŸÄ±daki baÄŸlamÄ± kullan.
    2. CevabÄ± maddeler halinde, okunaklÄ± ver.
    3. Bilgi yoksa kibarca "YÃ¶netmeliklerde bulamadÄ±m" de.
    
    BaÄŸlam: {context}
    Soru: {question}
    GeÃ§miÅŸ: {chat_history}
    
    Cevap:
    """
    PROMPT = PromptTemplate(template=template, input_variables=["chat_history", "context", "question"])
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 5}),
        return_source_documents=True, # KaynaklarÄ± gÃ¶stermek iÃ§in ÅŸart
        combine_docs_chain_kwargs={"prompt": PROMPT}
    )

# -----------------------------------------------------------------------------
# ARAYÃœZ (SIDEBAR)
# -----------------------------------------------------------------------------

if "logged_in" not in st.session_state: st.session_state.logged_in = False
if "messages" not in st.session_state: st.session_state.messages = []
if "chat_history" not in st.session_state: st.session_state.chat_history = []

with st.sidebar:
    st.title("ğŸ“ Mevzuat Paneli")
    
    # KullanÄ±cÄ± Verilerini YÃ¼kle
    users = {}
    if os.path.exists("users.json"):
        with open("users.json", "r") as f: users = json.load(f)
            
    if not st.session_state.logged_in:
        st.subheader("GiriÅŸ Yap")
        u = st.text_input("KullanÄ±cÄ± AdÄ±")
        p = st.text_input("Åifre", type="password")
        if st.button("GiriÅŸ Yap", type="primary"):
            if u in users and users[u]["password"] == p:
                st.session_state.logged_in = True
                st.session_state.username = u
                st.session_state.role = users[u]["role"]
                st.rerun()
            else: st.error("HatalÄ± kullanÄ±cÄ± adÄ± veya ÅŸifre!")
    else:
        st.success(f"HoÅŸ geldin, **{st.session_state.username}**")
        
        # --- YÃ–NETÄ°CÄ° KISMI ---
        if st.session_state.get("role") == "admin":
            st.divider()
            st.markdown("### ğŸ› ï¸ YÃ¶netici AraÃ§larÄ±")
            files = st.file_uploader("PDF YÃ¼kle", type=["pdf"], accept_multiple_files=True)
            
            if st.button("VeritabanÄ±nÄ± GÃ¼ncelle", type="primary"):
                if files:
                    if not os.path.exists("./veriler"): os.makedirs("./veriler")
                    for f in files:
                        with open(os.path.join("./veriler", f.name), "wb") as w: w.write(f.getbuffer())
                    
                    if os.path.exists(PERSIST_DIRECTORY): shutil.rmtree(PERSIST_DIRECTORY)
                    
                    with st.status("PDF'ler iÅŸleniyor...", expanded=True) as status:
                        st.write("ğŸ“„ Metinler okunuyor...")
                        chunks = load_and_process_pdfs()
                        st.write("ğŸ§  Yapay zeka hafÄ±zasÄ± oluÅŸturuluyor...")
                        if chunks:
                            Chroma.from_documents(chunks, HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"), persist_directory=PERSIST_DIRECTORY)
                            status.update(label="âœ… Ä°ÅŸlem Tamam!", state="complete", expanded=False)
                            time.sleep(1)
                            st.rerun()
        
        st.divider()
        if st.button("Ã‡Ä±kÄ±ÅŸ Yap"):
            st.session_state.logged_in = False
            st.rerun()

# -----------------------------------------------------------------------------
# ANA SOHBET EKRANI (CHAT)
# -----------------------------------------------------------------------------

st.title("ğŸ›ï¸ Mevzuat AsistanÄ±")
st.markdown("Ãœniversite yÃ¶netmelikleri hakkÄ±nda her ÅŸeyi sorabilirsin.")

if st.session_state.logged_in:
    vectordb = get_vector_db()
    
    if vectordb:
        # Eski mesajlarÄ± gÃ¶ster
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

        # Yeni soru giriÅŸi
        if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.chat_message("assistant"):
                placeholder = st.empty()
                placeholder.markdown("âš¡ *DÃ¼ÅŸÃ¼nÃ¼yor...*")
                
                try:
                    chain = get_llm_chain(vectordb)
                    res = chain({"question": prompt, "chat_history": st.session_state.chat_history})
                    answer = res['answer']
                    
                    # KaynaklarÄ± GÃ¼zelleÅŸtirme
                    sources = []
                    seen = set()
                    for doc in res['source_documents']:
                        name = os.path.basename(doc.metadata.get('source', 'Belge'))
                        page = doc.metadata.get('page', 0) + 1
                        key = f"{name} (Sayfa {page})"
                        if key not in seen:
                            sources.append(key)
                            seen.add(key)
                    
                    final_text = f"{answer}\n\nğŸ“š **Referanslar:**\n" + "\n".join([f"- {s}" for s in sources])
                    
                    # --- DAKTÄ°LO EFEKTÄ° (Geri DÃ¶ndÃ¼!) ---
                    def stream():
                        for word in final_text.split(" "):
                            yield word + " "
                            time.sleep(0.02)
                    placeholder.write_stream(stream)
                    # ------------------------------------

                    st.session_state.messages.append({"role": "assistant", "content": final_text})
                    st.session_state.chat_history.append((prompt, answer))
                
                except Exception as e:
                    placeholder.error(f"Bir hata oluÅŸtu: {e}")
    else:
        st.warning("âš ï¸ Sistem ÅŸu an boÅŸ. LÃ¼tfen yÃ¶netici panelinden PDF yÃ¼kleyerek veritabanÄ±nÄ± oluÅŸturun.")
else:
    st.info("ğŸ‘ˆ LÃ¼tfen sol panelden giriÅŸ yapÄ±nÄ±z.")