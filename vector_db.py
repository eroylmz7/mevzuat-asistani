import os
import shutil
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from data_ingestion import load_and_process_pdfs

# Ayarlar
PERSIST_DIRECTORY = "./chroma_db_store"  # VeritabanÄ±nÄ±n kaydedileceÄŸi klasÃ¶r

def create_vector_db():
    print("ğŸš€ VektÃ¶r VeritabanÄ± oluÅŸturma sÃ¼reci baÅŸlÄ±yor...")

    # 1. Verileri HazÄ±rla
    chunks = load_and_process_pdfs()
    if not chunks:
        print("âŒ Ä°ÅŸlenecek veri bulunamadÄ±. LÃ¼tfen 'veriler' klasÃ¶rÃ¼nÃ¼ kontrol et.")
        return

    # 2. Embedding Modelini YÃ¼kle
    # Proje planÄ±nda embedding kullanÄ±mÄ± belirtilmiÅŸtir [cite: 21]
    print("ğŸ§  Embedding modeli yÃ¼kleniyor (HuggingFace)...")
    # Not: Plandaki 'BAAI/bge-m3' modeli bÃ¼yÃ¼k olabilir, baÅŸlangÄ±Ã§ iÃ§in 
    # TÃ¼rkÃ§e desteÄŸi Ã§ok daha gÃ¼Ã§lÃ¼ olan model
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    # 3. VektÃ¶r VeritabanÄ±nÄ± OluÅŸtur ve Kaydet (Indexing)
    # Varsa eskisini temizle (temiz bir baÅŸlangÄ±Ã§ iÃ§in)
    if os.path.exists(PERSIST_DIRECTORY):
        shutil.rmtree(PERSIST_DIRECTORY)
        print(f"ğŸ§¹ Eski veritabanÄ± temizlendi: {PERSIST_DIRECTORY}")

    print("ğŸ’¾ VektÃ¶rler oluÅŸturuluyor ve ChromaDB'ye kaydediliyor...")
    
    # ChromaDB oluÅŸturma [cite: 22]
    db = Chroma.from_documents(
        documents=chunks,
        embedding=embedding_model,
        persist_directory=PERSIST_DIRECTORY
    )
    
    # BelleÄŸe kaydet (yeni sÃ¼rÃ¼mlerde otomatik olabilir ama garanti olsun)
    # db.persist() # Langchain gÃ¼ncel sÃ¼rÃ¼mlerinde otomatik yapÄ±lÄ±yor.

    print(f"BAÅARILI! VeritabanÄ± '{PERSIST_DIRECTORY}' klasÃ¶rÃ¼ne kaydedildi.")
    print(f"Toplam {len(chunks)} parÃ§a vektÃ¶rleÅŸtirildi.")

if __name__ == "__main__":
    create_vector_db()