import os
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
import json
import re

# --- 1. GEÃ‡MÄ°ÅÄ° HATIRLAYAN SORU DÃœZENLEYÄ°CÄ° ---
def reformulate_question(question, chat_history, api_key):
    if not chat_history:
        return question

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=api_key,
        temperature=0.1
    )
    
    history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history[-4:]])

    prompt = f"""
    GÃ–REV: Sohbet geÃ§miÅŸine bakarak kullanÄ±cÄ±nÄ±n son sorusunu tek baÅŸÄ±na anlaÅŸÄ±lÄ±r hale getir.
    
    SOHBET GEÃ‡MÄ°ÅÄ°:
    {history_text}
    
    SON SORU: "{question}"
    
    KURALLAR:
    - Soru "SÃ¼resi ne kadar?", "KaÃ§ kredi?" gibi eksikse, geÃ§miÅŸten Ã¶zneyi (Ã–rn: Lisans Mezuniyeti) bul ve tamamla.
    - Soru zaten netse aynen bÄ±rak.
    
    DÃœZENLENMÄ°Å SORU:
    """
    
    try:
        return llm.invoke(prompt).content.strip()
    except:
        return question
    
# --- YARDIMCI FONKSÄ°YON: GEMINI RERANKER (AKILLI HAKEM) ---
def rerank_documents(query, docs, api_key):
    """
    VektÃ¶r veritabanÄ±ndan gelen kaba sonuÃ§larÄ± (25 tane),
    Gemini'ye okutup 'GerÃ§ekten alakalÄ± mÄ±?' diye puanlatÄ±r ve eler.
    """
    reranker_llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", # HÄ±zlÄ± ve geniÅŸ context iÃ§in ideal
        google_api_key=api_key,
        temperature=0.0
    )

    # Belgeleri numaralandÄ±rÄ±p LLM'e sunuyoruz
    doc_text = ""
    for i, doc in enumerate(docs):
        # Dosya adÄ±nÄ± ve iÃ§eriÄŸi birleÅŸtiriyoruz
        source = os.path.basename(doc.metadata.get("source", "Bilinmiyor"))
        doc_text += f"\n[ID: {i}] (Kaynak: {source}) -> {doc.page_content[:400]}...\n"

    rerank_prompt = f"""
    GÃ–REV: AÅŸaÄŸÄ±daki belge parÃ§alarÄ±nÄ± kullanÄ±cÄ±nÄ±n sorusuna olan alaka dÃ¼zeyine gÃ¶re deÄŸerlendir.
    
    SORU: "{query}"
    
    ADAY BELGELER:
    {doc_text}
    
    KURALLAR:
    1. Soruda Ã¶zellikle  Lisans ile ilgili mi LisansÃ¼stÃ¼ ile ilgili mi soru sorulmuÅŸ dikkat et.
    2. Soru "Staj" ise, "YÃ¶nerge" belgelerine Ã¶ncelik ver.
    3. Soruya net cevap iÃ§eren belgeleri seÃ§.
    
    Ã‡IKTI FORMATI (Sadece JSON):
    {{
        "selected_indices": [en iyi belgenin ID'si, ikinci en iyi ID, ...]
    }}
    En fazla 5 belge seÃ§.
    """
    try:
        response = reranker_llm.invoke(rerank_prompt).content
        
        # --- JSON TEMÄ°ZLÄ°K MEKANÄ°ZMASI (YENÄ°) ---
        
        cleaned_response = re.sub(r"```json|```", "", response).strip()
        
        selected_data = json.loads(cleaned_response)
        selected_indices = selected_data.get("selected_indices", [])
        
        # SeÃ§ilenleri dÃ¶ndÃ¼r
        return [docs[i] for i in selected_indices if i < len(docs)]
    except:
        # Hata olursa en iyi ihtimalle ilk 5'i dÃ¶ndÃ¼r 
        return docs[:5]

def generate_answer(question, vector_store, chat_history):
    
    # --- 1. GÃœVENLÄ°K ---
    if "GOOGLE_API_KEY" in st.secrets:
        google_api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        return {"answer": "Hata: Google API Key bulunamadÄ±.", "sources": []}

    refined_question = reformulate_question(question, chat_history, google_api_key)
    
    
    # --- 2. ANALÄ°ST AJAN (Sorgu ZenginleÅŸtirme) ---
    llm_translator = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        google_api_key=google_api_key,
        temperature=0.1 
    )
    
    translation_prompt = f"""
    Soru: "{refined_question}"

    GÃ–REV: KullanÄ±cÄ± sorusunu analiz et ve arama motoru iÃ§in SADECE GEREKLÄ°YSE ek terim ekle.
    
    ANALÄ°Z MANTIÄI (SADE):
    1. EÄER SORU "LÄ°SANSÃœSTÃœ" Ä°LE Ä°LGÄ°LÄ°YSE:
       - (Ä°puÃ§larÄ±: Tez, JÃ¼ri, Yeterlik, DanÄ±ÅŸman, EnstitÃ¼, Seminer, TÄ°K, ALES)
       - EKLE: "LÄ°SANSÃœSTÃœ EÄÄ°TÄ°M YÃ–NETMELÄ°ÄÄ°"

    2. EÄER SORU "LÄ°SANS"  Ä°LE Ä°LGÄ°LÄ°YSE:
       - (Ä°puÃ§larÄ±: Ã‡AP, Yandal, Yaz Okulu, Tek Ders, BÃ¼tÃ¼nleme, DC, DD, Azami SÃ¼re)
       - EKLE: "LÄ°SANS EÄÄ°TÄ°M YÃ–NETMELÄ°ÄÄ°"

    3. EÄER SORU "UYGULAMA / STAJ" Ä°LE Ä°LGÄ°LÄ°YSE (YENÄ° KURAL):
       - (Ä°puÃ§larÄ±: Staj, Ä°ME, UygulamalÄ± EÄŸitim, Ä°ÅŸ Yeri EÄŸitimi, Grup)
       - EKLE: "UYGULAMALI EÄÄ°TÄ°M YÃ–NERGESÄ°"
       

    4. DÄ°ÄER DURUMLARDA:
       - Sadece "MEVZUAT" ekle.

    Sadece eklenecek anahtar kelimeleri yaz:
    """
    
    try:
        official_terms = llm_translator.invoke(translation_prompt).content.strip()
        hybrid_query = f"{refined_question} {official_terms}"
    except:
        hybrid_query = refined_question

    # --- 3. RETRIEVAL (KARARLI MOD) ---
    try:
        # KarmaÅŸÄ±k if-else'i kaldÄ±rdÄ±k. Tek ve gÃ¼Ã§lÃ¼ bir standart kullanacaÄŸÄ±z.
        initial_docs = vector_store.max_marginal_relevance_search(
            hybrid_query,
            k=25,             
            fetch_k=300,      
            lambda_mult=0.65  
        )
    except Exception as e:
        return {"answer": f"VeritabanÄ± hatasÄ±: {str(e)}", "sources": []}
    
  
# --- 3. RE-RANKING (AKILLI ELEME) ğŸ”¥ ---
    # 25 belgeyi al, Gemini'ye ver, en iyi 5 tanesini seÃ§tir.
    # Bu aÅŸama "Lisans vs YÃ¼ksek Lisans" karÄ±ÅŸÄ±klÄ±ÄŸÄ±nÄ± %100 Ã§Ã¶zer.
    final_docs = rerank_documents(refined_question, initial_docs, google_api_key)

    # --- 4. FORMATLAMA ---
    context_text = ""
    sources = []

    for doc in final_docs:
        content = doc.page_content.replace("\n", " ").strip()
        filename = os.path.basename(doc.metadata.get("source", "Bilinmiyor"))
        page = int(doc.metadata.get("page", 0)) + 1 if "page" in doc.metadata else 1
        
        context_text += f"\n--- KAYNAK: {filename} (Sayfa {page}) ---\n{content}\n"
        if filename not in sources:
            sources.append(filename)

    # --- 5. CEVAPLAYICI (HUKUKÃ‡U MODU) ---
    llm_answer = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        google_api_key=google_api_key,
        temperature=0.2 # YaratÄ±cÄ±lÄ±k 
    )
    
    final_template = f"""
    Sen Bursa UludaÄŸ Ãœniversitesi mevzuat asistanÄ±sÄ±n. 
    Elinizdeki belgeleri (context) kullanarak soruya (question) en doÄŸru, resmi ve net cevabÄ± ver.

    ELÄ°NDEKÄ° BELGELER (context):
    {context_text}

    SORU: {refined_question}

    ---  CEVAPLAMA KURALLARI ---

    KURAL 1: HÄ°YERARÅÄ° 
    - Ã–zel dÃ¼zenleme > Genel dÃ¼zenleme
    - YÃ¶nerge/Uygulama EsaslarÄ± > YÃ¶netmelik

    KURAL 2: SENTEZ VE BÄ°RLEÅTÄ°RME
    - Bilgiler parÃ§a parÃ§a olabilir (Ã¶rn: Bir maddede sÃ¼re, diÄŸerinde AKTS yazar). Gerekirse bunlarÄ± birleÅŸtirerek bÃ¼tÃ¼nlÃ¼klÃ¼ cevap ver.
        Ã–rnek: "lisans mezuniyet ÅŸartlarÄ± nelerdir?" sorusu
    - SayÄ±sal deÄŸerler (20 gÃ¼n, %70, 240 AKTS gibi) Ã¶zellikle dikkatli ara. Cevap sayÄ±sal bir deÄŸer gerektirebilir.

    KURAL 3: REFERANS
    - Bilgiyi hangi dosyadan aldÄ±ÄŸÄ±nÄ± parantez iÃ§inde belirt. Ã–rn: (uygulamali_egitimler.pdf)

    KURAL 4: DÃœRÃœSTLÃœK
    - Bilgi yoksa uydurma, "Belgelerde bulunmamaktadÄ±r" de.

    CEVAP:
    """
    
    try:
        answer = llm_answer.invoke(final_template).content
        
        # --- DEÄÄ°ÅÄ°KLÄ°K BURADA: CEVAP YOKSA KAYNAK GÄ°ZLE  ---
        # EÄŸer cevapta "bulunamadÄ±", "yoktur" gibi ÅŸeyler geÃ§iyorsa kaynaklarÄ± boÅŸalt.
        negative_signals = ["bulunmamaktadÄ±r", "bilgi yok", "rastlanmamÄ±ÅŸtÄ±r", "yer almamaktadÄ±r", "belirtilmemiÅŸtir"]
        
        if any(signal in answer.lower() for signal in negative_signals):
            final_sources = [] # BoÅŸ liste dÃ¶ndÃ¼r (BÃ¶ylece UI'da kutu Ã§Ä±kmaz)
        else:
            final_sources = sources[:5] # Sadece ilk 5 dosya adÄ±

        return {"answer": answer, "sources": final_sources}

    except Exception as e:
        return {"answer": f"Cevap oluÅŸturulurken hata: {str(e)}", "sources": []}